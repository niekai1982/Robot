

- 感知技术支撑学科
  - 计算机科学、人工智能、认知心理学、神经科学，还应包括哲学和数学

- 视觉科学研究领域变得更加技术化、更加数据化，更加“神经化”



#### Google Research



Machine Perception



Research in machine perception tackles the hard problems of understanding images, sounds, music and video. In recent years, our computers have become much better at such tasks, enabling a variety of new applications such as: content-based search in Google Photos and Image Search, natural [handwriting](https://googleresearch.blogspot.com/2015/04/google-handwriting-input-in-82.html) interfaces for Android, [optical character recognition](https://googleresearch.blogspot.com/2015/05/paper-to-digital-in-200-languages.html) for Google Drive documents, and recommendation systems that understand music and YouTube videos. Our approach is driven by algorithms that benefit from processing very large, partially-labeled datasets using parallel computing clusters. A good example is our recent work on object recognition using a novel deep convolutional neural network architecture known as [Inception](https://research.google.com/pubs/pub43022.html) that achieves state-of-the-art results on academic benchmarks and allows users to easily search through their large collection of Google Photos. The ability to mine meaningful information from multimedia is broadly applied throughout Google.

https://research.google/teams/perception/



#### Georgia Institute of Technology

Georgia Tech, School of Interactive Computing,Robotics & Computational Perception

> 佐治亚理工学院



Robotics and computational perception research at Georgia Tech runs from engineering to machine learning, from locomotion to autonomous ethical behavior in robotic machines. Our work is focused in two of our research centers and labs: The Robotics and Intelligent Machines (RIM) Center at Georgia Tech and the Computational Perception Lab (CPL).

RIM leverages the Institute’s strengths and resources by reaching across traditional boundaries to embrace a multidisciplinary approach. The College of Computing, College of Engineering and the Georgia Tech Research Institute play key, complementary roles through Tech's traditional expertise in interactive and intelligent computing, control and mechanical engineering. Emphasizing personal and everyday robotics, as well as the future of automation, RIM faculty help students understand and define the future role of robotics in society.

CPL was developed to explore and develop the next generation of intelligent machines, interfaces and environments for modeling, perceiving, recognizing, and interacting with humans. CPL domains of interest include computer vision/perception, computer graphics, computer animation, human-computer interaction, digital special effects, artificial intelligence, pattern recognition, machine learning, robotics, aware home/environments, audio processing, ubiquitous computing/sensing, eldercare technologies, motion analysis, and computational music.



#### Visual Perception Lab of Gerrit Maus

> Gerrit Maus, **于2015年10月在南洋理工大学开始了他的独立科学研究**。

https://www.x-mol.com/news/15762

Extrapolation and Interpolation in Visual Perception

Every day we use our sense of vision to perceive our surroundings and to interact with things in our environment. For successful interactions with things around us, it is essential to have accurate information about where things are. Oftentimes, however, our eyes cannot give us accurate information about where objects around us are located.

![Rafael Nadal](https://tva1.sinaimg.cn/large/0081Kckwgy1gmbmpplytjj308c06k3yr.jpg)

For example, when the objects we want to interact with are moving (e.g. when we try to hit a tennis ball), delays in the pathway from the eyes to the brain mean that our brains receive slightly outdated position information. In other situations, there are large gaps in the information from the eyes, which can be spatial gaps (e.g. when objects fall into the blind spot on the retina) or temporal gaps (e.g. when we blink).

![test](https://blogs.ntu.edu.sg/perception/files/2015/10/Blink-of-an-eye-Super-Slow-Motion-1ldfi3d.mp4?_=1)



Despite these limitations in the sensory input, we excel at interacting with the world around us like no artificial system. We are able to hit fast moving tennis balls despite the delays in our nervous system. We don’t see holes in the world where our blind spots are, and we don’t see the world disappear and reappear with every eye blink. This means that the brain must have evolved sophisticated mechanisms to deal with delays and discontinuities in its sensory input. It is extrapolating and interpolating from the limited available information to build a prediction and a unified conscious percept of the world around us.

![perception-brainscan](https://tva1.sinaimg.cn/large/0081Kckwgy1gmbmpp8thdj308c06ddfy.jpg)

To figure out how these mechanisms work, I study a number of fascinating perceptual illusions and phenomena. In my research, I use behavioral experiments (psychophysics) in healthy participants and patients with brain damage, eye tracking, brain imaging (fMRI), and transcranial magnetic stimulation (TMS) to try to unravel the mysteries of extrapolation and interpolation in visual perception.